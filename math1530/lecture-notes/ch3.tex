\documentclass[math1530-lecture-notes]{subfiles}
\begin{document}

\chapter{Rings: Part I}

Unlike groups, which were completely new, the concept of a \textbf{ring} is mildly familiar! Some
examples of rings include:
\begin{itemize}
  \item $\Z,\ \Q,\ \R$, and $\C$ are rings ($\Q,\ \R$, and $\C$ are actually \textbf{fields}, a
    special type of ring; such is a discussion for later)
  \item The set of integers modulo $m$ is a ring
\end{itemize}

These examples all share something in common: they each have two operations, "addition" and
"multiplication", and each operation individually satisfies some axioms, along with the \~great and
powerful\~ distributive law.

In general, a ring is a set with two operations satisfying a bunch of axioms that are modeled after
the properties of addition and muliplication of integers. We will later formalize this; but first, a
little number theory.

\section{Review of Number Theory}

\subsection{Equivalence Relations}

We first introduce the notion of \textbf{equivalence relations}; while not strictly related to
number theory, equivalence relations will be significant for modular arithmetic.

\begin{definition}[Equivalence Relations]{}
  An \textbf{equivalence relation} on a set $S$ is a relation ``$\sim $'' satisfying
  \begin{enumerate}
    \item \textbf{Reflexivity}: For $a\in S$, $a\sim a$
    \item \textbf{Symmetry}: For $a,b\in S$, $a\sim b$ implies $b\sim a$ 
    \item \textbf{Transitivity}: For $a,b,c\in S$, if $a\sim b$ and $b\sim c$, then $a\sim c$.
  \end{enumerate}
  $a\sim b$ means $a$ is ``related'' to $b$; $a\not\sim b$ means $a$ is ``not related'' to $b$.

  Given an $a\in S$, the \textbf{equivalence class} of $a$ is \[
    S_a = \{b\in S\mid b\sim a\} 
  .\] Note that $S_a$ is never empty; it always contains $a$.
\end{definition}

Some examples of equivalence relations are equality ($=$) and congruence $\mod{m}$; on the other
hand, order (e.g. $\le $) is \textbf{not} an equivalence relation (symmetry does not hold).

We now look further into the congruence $\mod{m}$ equivalence relation.

\begin{example}
  Given $a \in \Z$, $b \equiv a\mod{m}$ iff \[
    n | b-a \iff b - a = kn,\ k\in \Z \iff b = a + kn
  .\] So $\Z_a$ actually forms a coset of $n\Z$:
  \begin{align*}
    \Z_a &= \{b\in \Z\mid b\equiv a\mod{m}\}  \\
    &= \{a+kn\mid k\in \Z\}  \\
    &= a+n\Z
  .\end{align*}
  That is, each equivalence class for congruence $\mod{m}$ is actually a coset of $m\Z$ in $\Z$: \[
    \Z / m\Z = ~\text{set of cosets of $m\Z$ in $\Z$}~
  .\] 
\end{example}

\begin{theorem}[]{}
  Let $S$ be a set with an equivalence relation $\sim $. Then
  \begin{enumerate}
    \item If $a,b\in S$, then either \[
        S_a \cap S_b = \varnothing ~\text{or}~ S_a = S_b
      .\] 
    \item Let $\{ C_i \}_{i\in I}$ be the disjoint equivalence classes of $S$. Then \[
        S = \coprod_{i\in I}C_i
      .\] In particular, if $S$ is finite, then \[
        \left| S \right| = \left| C_1 \right|+ \ldots+\left| C_n \right|  
      .\] 
  \end{enumerate}
\end{theorem}

\subsection{Modular Arithmetic}

We first observe an important characteristic of the $\gcd$:
\begin{proposition}[]{}
  Given integers $u,v$, there exists integers $x,y$ such that \[
    ux+vy = \gcd{(u, v)}
  .\] $x,y$ can be found using the \textbf{Euclidean algorithm}.
\end{proposition}

This result leads us to an important proposition that facilitates equivalence relations in $\Z /
m\Z$:
\begin{proposition}[]{}
  $ax \equiv b\mod{m}$ is solvable if and only if \[
    \gcd{(a,m)}|b
  .\] 
\end{proposition}
\begin{proof}[Proof]
  First, suppose $ax\equiv b\mod{m}$ is solvable. It follows that \[
    m | ax-b
  .\] So, we can find $k\in \Z$ such that $ax-b=km$ is $b=ax-km$. From this, we get that any integer
  that divides both $a$ and $m$ must divide $b$; in particular, $\gcd{(a,m)}|b$.

  Conversely, if $\gcd{(a,m)}|b$, then $b=c\gcd{(a,m)}$ for some $c\in \Z$. Using the Euclidean
  algorithm to find $x,y$ with \[
    ax+ym=\gcd{(a,m)}
  ,\] and multiplying by $c$ to get \[
    a(cx) + y(mc) = c\gcd{(a,m)}=b
  ,\] we have $a(cx)\equiv b\mod{m}$, so the congruence is solvable.
\end{proof}

One natural followup is: \begin{center}
  When does $ax\equiv 1\mod{m}$ have a solution?
\end{center}
From the proposition above, \textbf{only if $ \gcd{(a,m)}=1$}; that is, only if $a$ and $m$ are
relatively prime. Rephrasing, if $a$ and $m$ are relatively prime, then $a$ has a unique
multiplicative inverse in $\Z / m\Z$.

\section{Abstract Rings and Ring Homomorphisms}

\begin{definition}[Rings]{}
  A \textbf{ring} $R$ is a set with two operations, generally called \textbf{addition} and
  \textbf{multiplication} and written
  \begin{align*}
    \underbrace{a+b}_{\text{addition}} &&\text{and}&& \underbrace{a\cdot b
    ~\text{or}~ab}_{\text{multiplication}}
  \end{align*}
  satisfying the following axioms:
  \begin{enumerate}
    \item The set $R$ with addition law $+$ is an Abelian group, with identity $0$ (or $0_R$).
    \item The set $R$ with multiplication law $\cdot $ is a \textbf{monoid} (associative, identity,
      \textbf{but no inverse}), with identity $1$ (or $1_R$\footnote{to avoid the trivial ring, we
      require $1_R\neq 0_R$; however, this is not strictly required}).
    \item \textbf{Distributive Law}: For all $a,\ b,\ c\in R$, we have
      \begin{align*}
        a\cdot (b+c)=a\cdot b+a\cdot c && \text{and} && (b+c)\cdot a= b\cdot a+c\cdot a
      .\end{align*}
    \item If, in addition to these three properties, $a\cdot b=b\cdot a$ for all $a,\ b\in R$, then
      $R$ is a \textbf{commutative} ring.
  \end{enumerate}
\end{definition}

Experience with the integers seems to suggest that $0_R\cdot a=0_R$, and $(-a)\cdot (-b)=a\cdot b$;
yet why are these true? $0_R$ is the definition of the identity element for \textit{addition}, so
why should it say anything about \textit{multiplication}? Similarly, $-a$ relates to the definition
of \textit{additive} inverse, but what does that tell us about its product with other elements in
$R$? To show these intuitively obvious claims, we need the distributive law.

\begin{proposition}[]{}
  \begin{enumerate}
    \item $0_R\cdot a=0_R$ for all $a\in R$.
    \item $(-a)\cdot (-b)=a\cdot b$ for all $a,\ b\in R$. In particular, we have $(-1_R)\cdot a=-a$.
  \end{enumerate}
\end{proposition}
\begin{proof}[Proof]
  \begin{enumerate}
    \item Note that $1_R=0_R+0_R$. Then
      \begin{align*}
        a &= 1_R\cdot a && [1_R~\text{is the muliplicative identity}~]\\
          &= (1_R+0_R)\cdot a &&[~\text{from above}~]\\
          &= 1_R\cdot a+0_R\cdot a && [~\text{from distributivity}~] \\
          &= a+0_R\cdot a
      .\end{align*}
      Adding $-a$ to both sides, we get \[
        0_R = 0_R + 0_R\cdot a
      ,\] and so $0_R \cdot a=0_R$.

    \item First, we show that $(-1_R)\cdot a=-a$:
      \begin{align*}
        a + (-1_R)\cdot a&= 1_R\cdot a+(-1_R)\cdot a \\
                         &= (1_R+ -1_R)\cdot a \\
                         &= 0_R\cdot a \\
                         &= 0_R
       .\end{align*}
       Hence $(-1_R)\cdot a$ is the inverse of $a$, and so $-a=(-1_R)\cdot a$.

       Now, observe that $-ab = (-a)b$ (this proof is left as an exercise for the reader). Then
       \begin{align*}
         (-a)\cdot (-b) + -ab &= (-a)\cdot (-b) + (-a)\cdot b \\
                              &= (-a)\cdot (-b+b) \\
                              &= (-a)\cdot 0_R \\
                              &= 0_R
      .\end{align*}
      Thus $(-a)\cdot (-b)$ is the inverse of $-ab$, and so $(-a)\cdot (-b)=ab$.
  \end{enumerate}
\end{proof}

Just like groups, we want to investigate maps \[
  \phi:R\to R'
\] from one ring to another that respect the \textit{ring-i-ness} of $R$ and $R'$. Since rings are
characterized by their addition and multiplication properties, we get the following definition.

\begin{definition}[Ring Homomorphisms]{}
  Let $R,\ R'$ be rings. A \textbf{ring homomorphism} from $R$ to $R'$ is a function $\phi:R\to R'$ 
  satisfying\footnote{we have the first axiom to disallow the boring and trivial zero map $\phi:R\to
  R'$, $\phi(a)=0_{R'}$.}
  \begin{enumerate}
    \item $\phi(1_R)=1_{R'}$
    \item $\phi(a+b) = \phi(a) + \phi(b)$ for all $a,b\in R$
    \item $\phi(a\cdot b)=\phi(a)\cdot \phi(b)$ for all $a,b\in R$
  \end{enumerate}

  The \textbf{kernel} of $\phi$ is the set of elements that are sent to 0: \[
    \ker(\phi)=\{ a\in R \mid \phi(a)=0_{R'} \}
  .\] 

  As with groups, $R$ and $R'$ are \textbf{isomorphic} if here is a bijective ring homomorphism
  $\phi:R\to R'$, and we call such a map an \textbf{isomorphism}.
\end{definition}

\section{Interesting Examples of Rings}

As described before, we have the four rings \[
  \Z \subset \Q \subset \R \subset \C
;\] we say that $\Z$ is a \textbf{subring} of $\Q$, and similarly for the others. Another example is
the ring of integers modulo $m$, $ \Z / m\Z$.

\begin{example}
  (Integers Modulo $m~\Z / m\Z$) We construct a ring $\Z / m\Z$ with integers, and determining
  equality if $a-b$ is a multiple of $m$. Formally, we define an equivalence relation on $\Z$ by the
  rule \begin{center}
    $a\equiv b$ if $a-b=km$ for some $k\in \Z$. We say $a$ is \textbf{congruent} to $b$ modulo $m$.
  \end{center}
  While $\Z / m\Z$ is not a subring of $\C$, there is a natural homomorphism \[
    \phi: \Z \longrightarrow \Z / m\Z,\ \phi(a)=a\mod{m}
  \] that assigns the integer $a$ to its equivalence class of all integers congruent to $a\mod{m}$.
  This homomorphism $\phi$ is called the \textbf{reduction $\mod{m}$ homomorphism}. The kernel of
  $\phi$ is the set of all multiples of $m$.
\end{example}

\begin{example}
  Another subring of $\C$ is the \textbf{ring of Gaussian integers} $\Z[i]$, which consists of \[
    \Z[i] = \{a+bi\mid a,b\in \Z\} 
  .\] The quantity $i$ represents the imaginary number (e.g. $\sqrt[]{-1} =i$), and addition and
  multiplication are defined following the usual rules of adding and multiplying complex numbers.

  In general, we can define a ring \[
    \F[z] = \{a+bz\mid a,b\in \F\} 
  \] for an arbitrary field and any number $z$.
\end{example}

\begin{example}
  Polynomials offer another method of creating bigger rings from already known rings. For any
  commutative ring $R$, we use $R$ to build the \textbf{ring of polynomials over $R$}, \[
    R[x] = \{ ~\text{polynomials $a_0+a_1x+\ldots+a_dx^{d}$ of all possible degrees with
    coefficients $ a_0,a_1,\ldots,a_d\in R$}~ \}
  .\] A common one we've seen before is $\R[x]$, but the rules of adding and multiplying polynomials
  hold in any commutative ring. Indeed, the rule for multiplying polynomials is a result of the
  distributive law!

  Now, consider the polynomial \[
    f(x) = a_0+a_1x+\ldots+a_dx^{d}\in R[x]
  .\] Then for any element $c\in R$, we can \textbf{evaluate $f$ at $c$} simply by substituting $x$ 
  with $c$: \[
    f(c) = a_0+a_1c+\ldots+a_dc^{d}\in R
  .\] When we first studied polynomials, we viewed them as functions, i.e. $f(x)$ defined a function
  $f:R\to R$. While these polynomial functions are interesting, they are almost never ring
  homomorphisms!

  Thus, we take another approach: using a particular $c\in R$, we define a function from the ring of
  polynomials $R[x]$ to the ring $R$: \[
    E_c: R[x]\longrightarrow R,\ E_c(f) = f(c)
  .\] We call $E_c$ the \textbf{evaluation at $c$ map}. If $R$ is commutative, then $E_c$ is a ring
  homomorphism, and its kernel is the set of polynomials that have a factor of $x-c$ (since $
  a_0+a_1(c-c)+\ldots+a_d(c-c)^{d}=0_R$).
\end{example}

\begin{example}
  One famous non-commutative ring is the \textbf{ring of quaternions}, \[
    \mathbb{H} = \{a+b\textbf{i}+c \textbf{j}+d\textbf{k} \mid a,b,c,d\in \R \} 
  .\] \textbf{$i$, $j$}, and \textbf{$k$} are the different square roots of $-1$, and although they
  commute with elements in $\R$, they don't commute with each other. To multiply two quaternions, we
  first use the distributive law, and then apply multiplication as specified in the quaternion
  group. Since $\mc{Q}$ is a non-commutative group, the ring of quaternions $\mathbb{H}$ is a
  non-commutative ring.
\end{example}

The ring of quaternions played an important role in the development of math and physics because of
the \textbf{cancellation law}: \begin{center}
  if you know that $\alpha$ and $\beta$ are real (or complex) numbers satisfying $\alpha\beta=0$,
  then either $ \alpha=0$ or $\beta=0$. It turns out that the same is true with quaternions!
\end{center} 

\begin{example}
  (Matrix Rings) There are also rings with matrix elements. Let \[
    M_2(\R)=\{\begin{pmatrix} a&b\\c&d \end{pmatrix} \mid a,b,c,d\in \R\} 
  \] denote the set of $2\times 2$ matrices with real entries. Matrices are added by their
  corresponding elements, and multiplied using matrix multiplication. With these operations, $
  M_2(\R)$ is a non-commutative ring. However, $ M_2(\R)$ does not satisfy the cancellation law: \[
    \begin{pmatrix} 1&0\\0&1 \end{pmatrix} \begin{pmatrix} 0&0\\0&1 \end{pmatrix} =\begin{pmatrix}
  0&0\\0&0 \end{pmatrix} 
.\] More generally, the set of $n\times n$ matrices over a ring $R$, $M_n(R)$, forms a
non-commutative ring.

There are many interesting homomorphisms from rings to matrix rings. For example, \[
  \C \hookrightarrow M_2(\R),\ x+yi\mapsto \begin{pmatrix} x&y\\-y&x \end{pmatrix}  
\] is an injective ring homomorphism (proof left as an exercise).
\end{example}

\begin{example}\label{ex21}
  For every ring $R$, there is a unique homomorphism \[
    \phi:\Z\longrightarrow R
  .\] To understand why, note that by homomorphism requirements we must have $\phi(1)=1_R$, and we
  must also have \[
    \phi(n)=\phi(1+\ldots+1)=\phi(1)+\ldots+\phi(1)
  .\] But we also need $\phi(0)=0_R$, and $\phi(-n)=-\phi(n)$, so there are really no other choices
  for $\phi$. In other words, the requirements that \[
    \phi(1)=1_R ~\text{and}~ \phi:\Z\longrightarrow R ~\text{is a homomorphism}~
  \] means that there is only one possibility for $\phi$. One still needs to check that $ \phi$ is a
  homo morph ism; such a proof is left as an exercise.
\end{example}

\section{Important Properties of Rings}

Some rings, such as $\Q,\ \R,\ \C$ have the special property that every non-zero element has a
multiplicative inverse. These rings are special, and we call them \textbf{fields.} 
\begin{definition}[Fields]{}
  A \textbf{field} is a commutative ring $R$ with the property that every non-zero element of $R$ 
  has a multiplicative inverse. In other words, for every non-zero $a\in R$, there is a $b\in R$ 
  satisfying $ab=1$.
\end{definition}

\begin{example}
  In addition to $\Z,\ \R$, and $\C$, there are also \textbf{finite fields}. One important example
  of a finite field is the ring $\Z / p\Z$, where $p$ is a prime. This follows from number theory:
  if $p \not| a$, then $ \gcd{(p,a)}=1$, and so $ax\equiv 1\mod{p}$ is solvable, e.g. there is a
  $b\in \Z / p\Z$ with $ab\equiv 1\mod{p}$. We denote this field $\F_{p}$.
\end{example}

Many other rings are not fields, such as $\Z$, $\Z[i]$, and $\R[x]$; however, they do have the nice
property of cancellation:
\begin{definition}[Cancellation Property]{}
  Let $R$ be a commutative ring. $R$ has the \textbf{cancellation property} if for every $a,b,c\in
  R$, \[
    ab=ac ~\text{with}~ a\neq 0 \iff b=c
  .\] 
\end{definition}

Rings that maintain the cancellation property are called \textbf{integral domains}:
\begin{definition}[Zero Divisors and Integral Domains]{}
  Let $R$ be a ring. An element $a\in R$ is a \textbf{zero divisor} if $a\neq 0$ and there is some
  non-zero $b\in R$ such that $ab=0$. The ring $R$ is an \textbf{integral domain} if it has no zero
  divisors. Equivalently, the ring $R$ is an integral domain if the only way to get $ab=0$ is if
  either $a=0$ or $b=0$.
\end{definition}

In fact, every field is an integral domain, and a ring $R$ is an integral domain if and only if it
has the cancellation property. Moreover, every integral domain is a subring of a field (the reader
should verify all of these statements). We will see later that the smallest such field is called the
\textbf{field of fractions over $R$}.


\section{Unit Groups and Product Rings}

In groups, we saw that many interesting subgroups and larger groups could be formed from a group.
Similarly, we get the notion in rings that every ring contains an interesting group, and smaller
rings can form larger rings.

\subsection{Unit Groups}

\begin{definition}[Unit Groups]{}
  Let $R$ be a commutative ring\footnote{For a non-commutative ring $R$, $a\in R$ is a
  \textbf{unit} if there are elements $b,c\in R$ such that $ab=ca=1$, i.e. the element $a$ needs
both a left- and right-inverse.}. The \textbf{group of units of $R$} is the subset $R^*$ of $R$
defined by \[
  R^* = \{a\in R\mid ~\text{there exists some $b\in R$ satisfying}~ ab=1\} 
,\] where group law is ring multiplication. Elements of $R^*$ are called \textbf{units}.
\end{definition}

\begin{proposition}[]{}
  The set of units $R^*$ of $R$ is a group, with group law being ring multiplication.
\end{proposition}
\begin{proof}[Proof]
  For each of the group axioms:
  \begin{itemize}
    \item Let $a_1,a_2\in R^*$, and let $b_1,b_2\in R^*$ be values such that $a_1b_1=1,\ a_2b_2=1$
      (we can say $b_1,b_2\in R^*$, not just $R$, since commutativity ensures that if $a\in R^*$,
      $b\in R^*$ as well). Then
      \begin{align*}
        1 &= a_1b_1a_2b_2 \\
        &= a_1a_2b_1b_2
      ,\end{align*} and since $b_1b_2\in R^*$ (multiplication is closed in monoids), we have $
      a_1a_2\in R^*$.
    \item $1\in R$ is the identity element.
    \item By definition, units have inverses.
    \item Multiplicative associativity is guaranteed by the ring axioms.
  \end{itemize}
  Hence $R^*$ is a group.
\end{proof}

\begin{example}
  Some unit groups include
  \begin{align*}
    \Z^*=\{ \pm 1 \}, && \Z[i]^*=\{ \pm 1,\pm i \}, && \R[x]^*=\R^*
  .\end{align*} Another interesting example is the ring $\Z[\sqrt[]{2} ]$, whose unit group has
  infinitely many elements. The proofs of these assertions is left as an exercise for the reader.
\end{example}

\begin{example}
  A ring $R$ is a field if and only if \[
    R^* = \{a\in R\mid a\neq 0\} = R \setminus \{ 0 \}
  ;\] in other words, every non-zero element has a multiplicative inverse.
\end{example}

We now explore the unit group of the ring $\Z / m\Z$.
\begin{proposition}[]{prop352}
  Let $m\ge 1$ be an integer. Then \[
    (\Z / m\Z)^* = \{a\mod{m}\mid \gcd{(a,m)}=1\} 
  .\] In particular if $m$ is a prime number, then $\Z / p\Z$ is a field (often denoted $\F_p$).
\end{proposition}
\begin{proof}[Proof]
  Suppose that $\gcd{(a,m)}=1$. Then by the Euclidean algorithm, we can find $u,v\in \Z$ satisfying
  $au+mv=1$. Hence \[
    au = 1-mv \equiv 1 \mod{m}
  .\] Thus $u$ is a multiplicative inverse for $a$ in the ring $\Z / m\Z$, so $a\mod{m}$ is in $(\Z
  / m\Z)^*$.

  In the other direction, suppose that $a\mod{m}\in (\Z / m\Z)^*$. Then for any $a\in \Z / m\Z$, we
  can find some $b\mod{m}\in \Z / m\Z$ such that \[
    (a\mod{m})(b\mod{m})=1\mod{m}
  .\] In other words, $ab\equiv 1\mod{(m)}$, so $ab-1=cm$ for some $c$. But then $ab-cm=1$, and so
  $\gcd{(a,m)}=1$, since any number dividing both $a,m$ divides $1$, which is only true for $1$.
\end{proof}


\subsection{Product Rings}

Now, we inspect building larger rings from smaller rings. Why make things more complicated? It turns
out that reversing this process, breaking up complicated rings into smaller, easier rings, can be
useful; one such example is the Chinese Remainder Theorem.

The building procedure is analogous to building products of groups, as well as constructing vector
spaces (e.g. $\R^{n}$, making $n$-tuples from $\R$).

\begin{definition}[Products of Rings]{}
  Let $R_1,\ldots,R_n$ be rings. The \textbf{product of $R_1,\ldots,R_n$} is the ring \[
    R_1\times \ldots\times R_n = \{(a_1,\ldots,a_n)\mid a_1\in R_1,\ldots,a_n\in R_n \} 
  .\] In other words, the product $R_1\times \ldots\times R_n$ is the set of $n$-tuples, where the
  first entry is chosen from $R_1$, second from $R_2$, etc. $R_1\times \ldots\times R_n$ becomes a
  ring using coordinate-wise addition and multiplication:
  \begin{align*}
    (a_1,\ldots,a_n)+(b_1,\ldots,b_n) &= (a_1+b_1,\ldots,a_n+b_n)\\
    (a_1,\ldots,a_n)\cdot (b_1,\ldots,b_n) &= (a_1\cdot b_1,\ldots,a_n\cdot b_n)
  .\end{align*} Proving $ R_1\times \ldots\times R_n$ is a group is left as an exercise for the
  reader.
\end{definition}

\begin{example}
  The product ring $\Z/ 2\Z \times  \Z / 3\Z$ has $6$ elements, \[
    (0,0),\ (1,0),\ (0,1),\ (0,2),\ (1,1),\ (1,2)
  .\] For example, addition and multiplication look like \[
    (1,1)+(1,2)=(0,0),\ (0,2)\cdot (1,2)=(0,1)
  .\] It turns out that $\Z / 2\Z \times  \Z / 3\Z \cong \Z / 6\Z$.\\

  However, $\Z / 2\Z\times \Z / 4\Z$ is \textbf{not} isomorphic to $\Z / 8\Z$. To see this, if \[
    \phi: \Z / 8\Z \longrightarrow \Z / 2\Z \times  \Z / 4\Z
  \] is a homomorphism, then by definition $\phi(1)=(1,1)$, so \[
  \phi(4)=\phi(1+1+1+1) = \phi(1)+\phi(1)+\phi(1)+\phi(1) = (1,1) + (1,1)+(1,1)+(1,1)=(0,0)
  .\] Hence $\ker(\phi)$ is non-trivial, so $\phi$ cannot be injective.
\end{example}

Now, we combine product rings and unit groups.
\begin{proposition}[]{}
  Let $R_1,\ldots,R_n$ be rings. Then the unit groups of the product is isomorphic to the product of
  the unit groups: \[
    \left( R_1\times \ldots\times R_n \right)^* \cong R_1^*\times \ldots\times R_n^*
  .\] 
\end{proposition}
\begin{proof}[Proof]
  If $(a_1,\ldots,a_n)\in \left( R_1\times \ldots\times R_n \right)^*$, then by definition there is
  a $(b_1,\ldots,b_n)\in \left( R_1\times \ldots\times R_n \right)^{*}$ satisfying \[
    (a_1,\ldots,a_n)\cdot (b_1,\ldots,b_n)=(1,\ldots,1)
  .\] However, this means that $a_ib_i=1$, so $a_i \in R_i^*$. Hence $(a_1,\ldots,a_n)\in
  R_1^{*}\times \ldots\times R_n^{*}$.

  Now, suppose $(a_1,\ldots,a_n)\in R_1^{*}\times \ldots\times R_n^{*}$. Then for $a_i\in R_i^{*}$,
  there exists some $b_i\in R_i^{*}$ such that $a_ib_i=1$. Then \[
    (a_1,\ldots,a_n)\cdot (b_1,\ldots,b_n)=(1,\ldots,1)
  .\] Hence $(a_1,\ldots,a_n)\in \left( R_1\times \ldots\times R_n \right)^*$.
\end{proof}


\section{Ideals and Quotient Rings}
Recall that in the ring $\Z / m\Z$, we pretend that $a,b\in \Z$ are "identical" if $a-b=km$ for some
$k\in \Z$. In other words, we get an equivalence relation \[
  a\equiv b\mod{m} ~\text{if}~ ab=km~(\text{$a-b$ is a multiple of $m$})
.\] We then defined $\Z / m\Z$ to be the set of equivalence classes.

Now, we attempt to generalize this construction to arbitrary (commutative) rings. We first start by
generalizing the concept ``being a multiple of $m$''. Why would we want this? 
\begin{itemize}
  \item First, it provides us with a new ring to explore; when is $\Z / m\Z$ a field? An integral
    domain? Moreover, when exploring conjectures, $\Z /m\Z$ provides a testing ground.
  \item Second, sometimes $\Z / m\Z$ is easier to work with than $\Z$. Consider the Diophantine
    equation \[
      x^{n}+y^{n}=z^{n}
    .\] Solving this can be notoriously difficult (PepeLaugh). However, since $\Z / m\Z$ is finite,
    we can use the natural ring map $\phi:\Z \longrightarrow \Z/m\Z$ for a variety of $m$'s to learn
    about the problem.
\end{itemize}

\begin{definition}[Ideals]{}
  Let $R$ be a commutative ring. An \textbf{ideal} of $R$ is a non-empty subset $I\subseteq R$ with
  the following two properties:
  \begin{itemize}
    \item If $a \in I$ and $b\in I$, then $a+b\in I$.
    \item If $a \in I$ and $r\in R$, then $ra\in I$.
  \end{itemize}
\end{definition}

Some examples of ideals include $m\Z\subseteq \Z$ (for any $m\in \Z$), $\{ 0 \}\subseteq R$ for any
ring $R$, and $R$ itself.

One way to create an ideal of $R$ is to start with one element in $R$ and take all of its multiples.
\begin{definition}[Principal Ideals]{}
  Let $R$ be a commutative ring, and let $c\in R$. The \textbf{principal ideal generated by $c$},
  denoted $cR$ or $(c)$, is the set of all multiples of $c$, \[
    cR = (c) = \{rc\mid r\in R\} 
  .\] Verifying that $cR$ is an ideal is straightforward, and left as an exercise. 
\end{definition}

The above examples still hold: $m\Z$, $ \{ 0 \}$, and $R$ are all principal ideals.

In some rings (e.g. $\Z,\ \Z[i],\ \R[x]$), every ideal is a principal ideal (such rings are called
\textbf{principal ideal domains}), although this is not immediately obvious. Moreover, this is not
true for rings like $\Z[i]$; there exist non-principal ideals.

\begin{example}
  Every ring has at least two ideals:
  \begin{itemize}
    \item the \textbf{zero ideal} \[
      (0)=0R=\{ 0 \}
    \] consisting of just the zero element, and the \textbf{unit ideal}\[
      (1)=1R=R
    \] consisting of the entire ring.
  \end{itemize}
  More generally, if $u\in R$ is a unit, then $uR = (u) = R$.
\end{example}

Just like products of rings, we can formulate a sense of building multiple ideals. A principal ideal
is generated by a single element in R; for a finite list of elements $c_1,\ldots,c_n\in R$, the
\textbf{ideal generated by $c_1,\ldots,c_n$} is \[
  (c_1,\ldots,c_n)=c_1R+\ldots+c_nR=\{r_1c_1+\ldots+r_nc_n\mid r_1,\ldots,r_n\in R\} 
.\] Verifying that this is an ideal is left as an exercise.

\begin{remark}
  (Proof Technique) Let $I$ be an ideal of $R$. If $1\in I$, then for every $r\in R$ we have $r\cdot
  1=r\in I$, so $I=R$ is the unit ideal. Conversely, if you can construct an ideal $I$ and prove
  $I=R$, we can often exploit this fact by using $1\in I$.
\end{remark}

Now, we can start crafting quotient rings $R/I$ by identifying pairs of $R$ if their difference is
in $I$, just like we did when defining $\Z / m\Z$: \begin{center}
  For an element $a\in R$, the set of $b\in R$ that are equivalent to $a$ consists of the set of $b$ 
  such that $a-b\in I$, or equivalently, such that $b$ is in the set $a+I$.
\end{center}
This parallel to the ring of integers modulo $m$ prompts the following definitions.
\begin{definition}[Cosets of Ideals]{}
  Let $R$ be a commutative ring, and let $I$ be an ideal of $R$. Then for every element $a\in R$,
  the \textbf{coset of $a$} is the set \[
    a+I=\{a+c\mid c\in I\} 
  .\] Note that $a$ is always an element of its coset, since $0\in I$. If $a,b\in R$ satisfy $b-a\in
  I$, then people often write \[
    b \equiv a\mod{I}
  \] and say ``$b$ is congruent to $a$ modulo $I$.''

  Given two cosets $a+I$ and $b+I$, we define their sum and product by the formulas
  \begin{align*}
    (a+I)+(b+I)=(a+b)+I, && (a+I)\cdot (b+I)=(a\cdot b)+I
  ,\end{align*} and we denote the collection of distinct cosets by $R / I$.
\end{definition}

Like $\Z / m\Z$, we wish to turn $R / I$ into a ring; it turns out that the above definitions
successfully define a commutative ring.

\begin{proposition}[]{}
  Let $R$ be a commutative ring, and let $I$ be an ideal of $R$.
  \begin{enumerate}
    \item Let $a+I,a'+I$ be two cosets. Then $a+I=a'+I$ if and only if $a'-a\in I$.
    \item Addition and multiplication of cosets is well-defined, in that it doesn't matter which
      element of the coset we use in the definition.
    \item Addition and multiplication of cosets in $R / I$ turn $R / I$ into a commutative
      ring.\footnote{To be precise, we must require that $I\neq R$, since if $I=R$, then $R/I$ only
      has one element, and we don't allow rings to have $1=0$.}
  \end{enumerate}
\end{proposition}
\begin{proof}[Proof]
  \begin{enumerate}
    \item Suppose $a+I=a'+I$. Then $a'=a+c$ for some $c\in I$. But then $a'-a=c\in I$, and so
      $a'-a\in I$.

      Now, suppose $a'-a\in I$. Then $a'-a=c\in I$ for some $c\in I$, so $a'=a+c,\ a=a'-c$. Thus any
      $\alpha\in a'+I$ can be written as $a'+b=a+(b+c)\in a+I$, and any $\beta\in a+I$ can be
      written as $\beta=a+b=a'+(b-c)\in a'+I$. Hence $a+I\subseteq a'+I,\ a'+I\subseteq a+I$, so
      $a+I=a'+I$.

    \item For addition: let $a,b,a',b'\in R$ be elements that satisfy $a\equiv a'\mod{I},\ b\equiv
      b'\mod{I}$; that is, $a'-a\in I,\ b'-b\in I$. By (1), $a+I=a'+I,\ b+I=b'+I$. Then \[
        a'=a+s,\ b'=b+t
      \] for some $s,t\in I$. But then $a'+b'=a+s+b+t=(a+b)+(s+t)$; and since $s+t\in I$, we have
      $a'+b'\equiv a+b\mod{I}$. Alternatively, $(a'+b')-(a+b)\in I$, so by (1) $(a+b)+I=(a'+b')+I$.

      For multiplication: let $a,b,a',b'\in R$ be elements whose cosets satisfy
      \begin{align*}
        a'+I=a+I ~\text{and}~b'+I=b+I
      .\end{align*} The assumption that $a+I=a'+I$ means that there is some $c\in I$ such that $a'=a+c$,
      and similarly the assumption that $b+I=b'+I$ means that there is some $d\in I$ such that $b'=b+d$
      (since $a'\in a+I$ means that $a'$ is of the form $a+c$ for some $c\in I$). It follows that \[
        a'b'=(a+c)(b+d)=ab+\underbrace{ad+cb+cd}_\text{This is in $I$, since $c,d\in I$.}
      .\] Since $c,d\in I$, $ad+cb+cd$ is also in $I$, and so $a'b'-ab=ad+cb+cd \in I$; and from (1), we
      see that $ab+I=a'b'+I$ are equal.
  \end{enumerate}
\end{proof}


\begin{remark}
  One way to view the quotient ring $R / I$ is to divide a ``pie'' of $R$ into its individual
  ``slices'', where each slice represents an element of $R / I$ (for instance, $\Z / 3\Z$ is divided
  into three slices: $3\Z,\ 1+3\Z,~\text{and}~2+3\Z$). Alternatively, one can view $a$ and $b$ as
  ``indistinguishable'' if $a-b\in I$. As we think of $1\sim 4$ in $\Z / 3\Z$, we can abstractly
  partition $\Z / 3\Z$ into colors; red might symbolize $3\Z$, green for $1+3\Z$, and blue for
  $2+3\Z$. Thus, $1,4,7$ would all be red, ``the same element''. 
\end{remark}

Ideals and homomorphisms are closely related. Review the following proposition carefully; it will be
used constantly.

\begin{proposition}[]{}
  \begin{enumerate}
    \item Let $R$ be a commutative ring. Then the map \[
        \pi: R\longrightarrow R/I,\ a\longmapsto a+I
      \] that sends an element to its coset is a surjective ring homomorphism with kernel $I$.
    \item Let $\phi: R\to R'$ be a ring homomorphism.
      \begin{itemize}
        \item The kernel of $\phi$ is an ideal of $R$ (recall that the kernel is $\ker(\phi)=\{a\in
          R\mid \phi(a)=0_{R'}\}$).
        \item The homomorphism is injective if and only if $\ker(\phi)=(0)$.
        \item Let $I_\phi=\ker(\phi)$. There is a well-defined injective ring homomorphism \[
            \overline{\phi}: R / I_\phi \longrightarrow R,\ \overline{\phi}(a+I_\phi)=\phi(a)
        .\] Moreover, if $\phi$ is surjective, then $\overline{\phi}$ is an isomorphism.
      \end{itemize}
  \end{enumerate}
\end{proposition}

\begin{proof}[Proof]
  To prove homomorphism:
  \begin{itemize}
    \item $\pi(0_R)=0+I=I=0_{R / I}$.
    \item $\pi(a+b)=(a+b)+I=(a+I)+(b+I)=\pi(a)+\pi(b)$, by definition of addition of cosets of
      ideals.
    \item $\pi(a\cdot b)=(a\cdot b)+I=(a+I)\cdot (b+I)=\pi(a)\cdot \pi(b)$, by definition of
      multiplication of cosets of ideals.
  \end{itemize}
  Hence $\pi:R\to R / I$ is a ring homomorphism. Next, recall that $\ker(\pi)=\{a \in R\mid
  \pi(a)=0_{R/I}\}.$ But $0_{R / I}=0+I$, so we need $\pi(a)=I=0+I$. For any $a+I,\ a+I=0+I$ iff
  $a-0=a\in I$; thus $\ker(\pi)=I$. Surjectivity is trivial: for any $a+I\in R / I$, $a\in R$, so
  $\phi(a)=a+I$. \\

  Now, let $\phi:R\to R'$ be a ring homomorphism. The kernel of $\phi$ is the set $\{a\in R\mid
  \phi(a)=0_{R'}\} $. For any $a,\ b\in \ker(\phi)$, we have $\phi(a+b)=\phi(a)+\phi(b)=0+0$, and so
  $a+b\in \ker(\phi)$. Next, let $c\in R$. For any $c\cdot a$, we have $\phi(c\cdot a)=\phi(c)\cdot
  \phi(a)=\phi(c)\cdot 0=0$, and so $c\cdot a\in \ker(\phi)$. Thus $\ker(\phi)$ forms an ideal of
  $R$.

  To prove injectivity iff $\ker(\phi)=(0)$:
  \begin{itemize}
    \item Suppose $\phi$ is injective. Then for any $a\in \ker(\phi)$, $\phi(a)=0=\phi(0)$, so
      $a=0$.
    \item Conversely, suppose $\ker(\phi)=(0)$. Suppose $\phi(a)=\phi(a')$. Then
      $\phi(a)-\phi(a')=\phi(a-a')$, so $a-a'\in \ker(\phi)$; but $\ker(\phi)=(0)$, so $a-a'=0
      \implies a=a'$. Hence $\phi$ is injective.
  \end{itemize}

  We finally prove well-definedness of $\overline{\phi}$. Suppose that $a+I_\phi=a'+I_\phi$ are two
  ways of writing a coset. We need to show $ \overline{\phi}(a)=\overline{\phi}(a')$. The assumption
  of $a+I_\phi=a'+I_\phi$ allows us to write  $a'=a+b$ for some $b\in I_\phi$. Thus \[
  \overline{\phi}(a'+I)=\phi(a')=\phi(a+b)=\phi(a)+\phi(b)=\phi(a)+0=\phi(a),\] and so
  $\overline{\phi}$ is well-defined. $\overline{\phi}$ being a ring homomorphism follows directly
  from $\phi$ being a ring homomorphism. To show injectivity, \[
    \overline{\phi}(a+I_\phi)=\overline{\phi}(b+I) \iff \phi(a)=\phi(b) \iff \phi(a-b)=0 \iff a-b\in
    I_\phi \iff a+I_\phi = b+I_\phi
  ,\] as desired (the second last step is accomplished because $ \phi(a-b)=0$ implies $a-b\in
  \ker(\phi)=I_\phi$).

  Finally, if $\phi$ is surjective, then so is $\overline{\phi}$: $\phi$ surjective implies any
  $a'\in R'$ can be written as $\phi(a)$; but then any $\phi(a)$ can be written as
  $\overline{\phi}(a+I_\phi)$; thus $\phi(a)=\overline{\phi}(\pi(a))=\overline{\phi}(a+I_\phi)$, and
  so $\overline{\phi}$ is surjective. We don't have to worry about $\pi$ ``eating up'' any $a\in R$:
  if $a\equiv b\mod{I_\phi}$, then $a=b+c$ for some $c\in I_\phi$, so \[
    \phi(a)=\phi(b+c)=\phi(b)+\phi(c)=\phi(b)+0=\phi(b)
  ,\] and so $\phi(a)=\phi(b)$. Hence any $\pi(a)=\pi(b)$ won't affect the surjectivity of
  $\overline{\phi}$.

  Therefore $\overline{\phi}$ is an isomorphism.
\end{proof}

\begin{definition}[Characteristics of Rings]{}
  Let $R$ be a ring, and let \[
    \phi:\Z\longrightarrow R
  \] be the unique homomorphism determined by $\phi(1)=1_R$ (see Example \ref{ex21}). The kernel of
  $\phi$ is an ideal of $\Z$, and recall that every ideal of $\Z$ is principal (therefore every
  ideal $I$ of $\Z$ is of the form $m\Z$); there is thus a unique integer $m\ge 0$ such that  \[
    \ker(\phi)=m\Z
  .\] That integer $m$ is called the \textbf{characteristic of the ring $R$}. 
\end{definition}

Another way to describe $m$ is that $m$ is the smallest integer such that \[
\phi(m)=\underbrace{1_R+\ldots+1_R}_\text{$m$ terms}=0_R
;\] or, if no such $m$ exists, then $m=0$ (the characteristic of $R$ is $0$).

\begin{example}
  The ring $\Z / m\Z$ has characteristic $m$, while the rings $\Z,\Q,\R,\C$ all have characteristic
  $0$. It follows from Proposition 3.31 that if a ring has characteristic $m$, then there is an
  injective ring homomorphism  \[
    \Z / m\Z \hookrightarrow R
  \] (this follows since characteristic $m$ implies $\ker(\phi)=m\Z$ for some $\phi: \Z\to R$, and
  every map $\Z / I_\phi=\Z/m\Z\to R$ is injective).
\end{example}

Note that when $m=0$, we aren't ``dividing by $0$.'' In general, the quotient of a ring $R$ by the
zero ideal $(0)$ is just $R:\ R / (0) = R$, since $R / (0)$ means we identify elements $a,b\in R$ as
congruent if $a-b=0$; or, $a=b$. Thus $R$ has infinitely many cosets $a+(0)$, and so $R / (0) =
R$.\\

Now, we move on to the \~Freshman's Dream\~. Many freshmen hope for $(a+b)^n=a^n+b^n$. Clearly, this
isn't true in $\R$; but is there a ring in which this is true? It turns out that yes, any ring with
prime characteristic possesses that possibility!

\begin{theorem}[Freshman's Dream]{}
  Let $p$ be a prime, and let $R$ be a commutative ring with characteristic $p$. Then the map \[
    f: R\longrightarrow R,\ f(a)=a^p
  \] is a ring homomorphism, called the \textbf{Frobenius homomorphism of $R$}. In particular, for
  all $a,b\in R$ and $n\ge 0$, we have \[
    (a+b)^{p^n}=a^{p^n}+b^{p^n}
  .\] 
\end{theorem}
\begin{proof}[Proof]
  Clearly $f(1)=1$, and preserving multiplication is clear: \[
    f(ab)=(ab)^p=(a^p)(b^p)=f(a)f(b)
  .\] For addition, we use the Binomial Theorem:
  \begin{align*}
    f(a+b)&= (a+b)^p \\
          &= \sum_{k=0}^{p} \binom{p}{k} a^{p-k}b^k \\
          &= a^p + b^p + \sum_{k=1}^{p-1} \binom{p}{k}a^{p-k}b^{k}
        .\end{align*}
  For any $1\le k\le p-1$, $\binom{p}{k}$ is a multiple of $p$: \[
    \binom{p}{k}= \frac{p!}{k!(p-k)!}=\frac{(p-k+1)\ldots(p-1)(p)}{k!}
  .\] Moreover, since $p$ is prime and $1\le k\le p-1$, none of $k!$ will cancel with $p$ (see
  Proposition 1.47 in the book). Since we're working in a ring with characteristic $p$, that means
  all the $\binom{p}{k}$ will be $0$. Hence the entire sum disappears, and we are left with \[
    f(a+b)=a^n+b^n=f(a)+f(b)
  .\] Thus $f$ is a ring homomorphism.

  To prove the freshman's dream, we use induction: the case $n=1$ is already proven, so suppose
  $n=k$ is true. Then \[
    (a+b)^{p^{k+1}}=((a+b)^{p^k})^p=(a^{p^k}+b^{p^k})^p = (a^{p^k})^p +
    (b^{p^k})^p=a^{p^{k+1}}+b^{p^{k+1}}
  .\] Thus the freshman dream holds for any $(a+b)^{p^n}$.
\end{proof}


\section{Prime Ideals and Maximal Ideals}

Primes hold great significance in number theory. Recall that an integer $p$ is prime if and only if
its only (positive) divisors are $1$ and $p$. Moreover, if $p$ divides any $ab$, then either
$p$ divides $a$ or $p$ divides $b$. We can rephrase this divisibility property for any arbitrary
ideal: if a product $ab$ is in the ideal $p\Z$, then either $a\in p\Z$ or $b\in p\Z$. Additionally,
we note that integral domains and fields are of particular interest; thus, we wish to find for which
ideals $I$ is the quotient ring $R / I$ an integral domain, and for which is it a field.


\begin{definition}[Prime Ideals]{}
  Let $R$ be a commutative ring. An ideal $I$ of $R$ is a \textbf{prime ideal} if $I\neq R$ and if,
  whenever $ab\in I$, then either $a\in I$ or $b\in I$.
\end{definition}

The contrapositive is also important: if $I$ is a prime ideal, and both $a\not\in I$ and $b\not\in
I$, then we have $ab\not\in I$.

\begin{example}
  Let $m\neq 0$. The ideal $m\Z$ is a prime ideal if and only if $\left| m \right| $ is a prime
  number.
\end{example}
\begin{example}
  Let $F$ be a field. For every $a,b \in F$ with $a\neq 0$, the principal ideal $(a+bx)F[x]$ is a
  prime ideal. For every $a,b,c\in F$ with $a\neq 0$ and $b^2-ac\neq d^2$ for any $d\in F$ 
  ($b^2-ac$ is not the square of any element), the principal ideal $(a^2+bx+c)F[x]$ is a prime
  ideal.
\end{example}

The largest possible ideal of $R$ that is not $R$ itself is also of interest.
\begin{definition}[Maximal Ideals]{}
  Let $R$ be a commutative ring. An ideal $I$ is a \textbf{maximal ideal} if $I\neq R$ and there is
  no ideal ``larger'' than $I$, or ``contained'' between $I$ and $R$; that is, for any ideal $J$, if
  $I\subseteq J\subseteq R$, then either $J=I$ or $J=R$.
\end{definition}

\begin{example}
  Let $p\in \Z$ be a prime number. Then the ideal $p\Z$ is both a prime ideal \textbf{and} a maximal
  ideal. This follows by combining Proposition \ref{prop352} (3.17 in the textbook), which says that
  $\Z / p\Z$ is a field, and the following Theorem \ref{thm373} (3.40 in the textbook), which says
  that in general, $R / I$ is a field if and only if $I$ is a maximal ideal.
\end{example}
\begin{example}
  In the ring $\Z[x]$ of polynomials with integer coefficients, the principal ideals $2\Z[x]$ and
  $x\Z[x]$ are prime ideals, but not maximal ideals, since they are properly contained in the ideal
  \[
    \{2a(x)+xb(x)\mid a(x),\ b(x)\in \Z[x]\} 
  \] generated by $2$ and $x$, and one can check that this ideal is not all of $\Z[x]$. Indeed, it
  is a non-principal maximal ideal.
\end{example}

Just as prime numbers in $\Z$ form the basic building blocks for all numbers (recall that any
integer can be represented uniquely as a product of prime numbers), the prime and maximal ideals of
$R$ are, in some sense, the basic building blocks underlying the algebraic (and geometric) structure
of $R$.\\

On the other hand, integral domains and fields are two particularly nice examples of rings. Thus,
the next theorem is both interesting and important.
\begin{theorem}[]{thm373}
  Let $R$ be a commutative ring, and let $I$ be an ideal with $I\neq R$.
  \begin{enumerate}
    \item $I$ is a prime ideal if and only if the quotient ring $R / I$ is an integral domain.
    \item $I$ is a maximal ideal if and only if the quotient ring $R / I$ is a field.
  \end{enumerate}
\end{theorem}
\begin{proof}[Proof]
  We first deal with the first statement:
  \begin{itemize}
    \item Suppose $I$ is a prime ideal. Let $a+I$ and $b+I$ be elements of $R / I$. If
      $(a+I)(b+I)=0+I=I$, then either $a+I=I$ or $b+I=I$. Thus at least one of $a+I$ and $b+I$ is
      equal to $0+I$, and so $R / I$ is an integral domain (since for any $a,b\in R / I$, if $a\cdot
      b=(a+I)(b+I)=0_{R / I}=0+I$, then one of $a+I,\ b+I$ is $0_{R / I}$).
    \item Conversely, suppose $R / I$ is an integral domain. Then for any $a+I,\ b+I\in R / I$, if
      $(a+I)(b+I)=0+I=I$, then either $a+I=I$ or $b+I=I$. This implies either $a\in I$ or $b\in I$ 
      (since $a+I=0+I$ implies $a-0=a\in I$).
  \end{itemize}
  Now, we move on to the second:
  \begin{itemize}
    \item Suppose $I$ is a maximal ideal. Let $a+I$ be a non-zero element of $R / I$ (e.g. $a+I\neq
      I$). To exploit the fact that $I$ is a maximal ideal, construct an ideal $J$ where \[
        J = \{ar+b\mid r\in R,\ b\in I\} 
      \] ($J$ being an ideal is left as an exercise). Taking elements of $J$ with $r=0$ shows that
      $I\subset J$, while taking $r=1,\ b=0$ shows that $a\in J$.  Since $a\not\in I$, $J$ is
      strictly larger than $I$; and since $I$ is a maximal ideal and $I\subsetneq J \subseteq R$, we
      have that $J=R$. In particular, $1\in J$. Thus there exists some $c\in R,\ b\in I$ such that
      $1=ac+b$. In terms of $R / I$, and using the fact that $b\in I$ implies $b+I=I$, we have \[
        1+I=(ac+b)+I=(ac+0)+I=ac+I=(a+I)(c+I)
      .\] Hence $a+I$ has a multiplicative inverse in $R / I$, and by definition $R$ is commutative,
      so $R / I$ is a field.
    \item Conversely, suppose $R / I$ is a field. Let $J$ be an ideal such that $I\subseteq
      J\subseteq R$. If $J=I$, we are done, so suppose $J\neq I$. Then for some $a\in J$, we have
      $a\not\in I$. Then the coset $a+I\neq I=0+I$, so $a+I$ is a non-zero element of $R / I$. Since
      $R / I$ is a field, $a+I$ has a multiplicative inverse $c+I$ for some $c\in R$; that is, \[
        1 + I = (a+I)\cdot (c+I)=ac+I
      ,\] so there is an element $b\in I$ such that $1=ac+b$. But $J$ is an ideal, so $a\in J$
      implies $ac\in J$. Additionally, since $b\in I\subset J$, we have $ac+b=1\in J$. But since
      $1\in J$, any $r\in R$ is in $J$: $r\cdot 1=r\in J$. Hence $J=R$, and so $I$ is a maximal
      ideal.
  \end{itemize}
\end{proof}

This theorem leads to a very slick corollary:
\begin{corollary}[]{}
  Every maximal ideal is a prime ideal.
\end{corollary}
\begin{proof}[Proof]
  If an ideal $I$ is a maximal ideal, then $R / I$ is a field. But $R / I$ is a field implies that
  $R / I$ is an integral domain, and thus $I$ is a prime ideal as well.
\end{proof}
Note that the converse does not always hold; Example 31 (3.39 in the textbook) illustrates prime
non-maximal ideals.
\begin{remark}
  It would be nice to say that any ring has at least one maximal ideal. It turns out that this is
  yet another statement equivalent to the Axiom of Choice!
\end{remark}



\end{document}
